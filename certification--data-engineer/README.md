# はじめに

このフォルダ配下には、data engineer の資格取得用対策の資材（ノートブック等）を格納している。

# 試験概要

- Databricks レイクハウスプラットフォームを使用して入門レベルのデータエンジニアリングタスクを完了する個人の能力を評価する
- レイクハウスプラットフォームとそのワークスペース、アーキテクチャ、機能についての理解が含まれる
- バッチ処理と増分処理、両方のパラダイムで Apache Spark SQL と Python を使用してマルチホップアーキテクチャ ETL タスクを実行する能力も評価する
- はエンティティの権限を維持しながら基本的な ETL パイプラインと Databricks SQL クエリーおよびダッシュボードを本番運用に導入する能力を評価する

# 試験の内容

運営元によると下記が公開されている。下記１つ１つについて説明できればよいと考えられるため、１つ１つまとめる。まとめたらチェックする TODO リストとして使う。

## セクション 1: Databricks レイクハウスプラットフォーム
- [x] データレイクハウスとデータウェアハウスの関係を説明する。
- [x] データレイクとの比較で、データレイクハウスにおけるデータ品質の改善点を特定する。
- [x] シルバーテーブルとゴールドテーブルを比較対照し、どのワークロードでソースとしてブロンズテーブルを使用し、どのワークロードでソースとしてゴールドテーブルを使用するのかを判断する。
- [x] データプレーンとコントロールプレーンに配置される要素や、顧客のクラウドアカウント内に存在する要素など、Databricks プラットフォームアーキテクチャに含まれる要素を特定する
- [x] All-Purpose クラスターとジョブクラスターの違いを理解する。
- [ ] Databricks Runtime を使用したクラスターソフトウェアのバージョン管理方法を特定する。
- [ ] クラスターをフィルタ処理して、ユーザーがアクセス可能なものを表示する方法を特定する。
- [ ] クラスターが終了する仕組みと、クラスターの終了が及ぼす影響を説明する。
- [ ] クラスターの再起動が役に立つシナリオを特定する。
- [ ] 同じノートブック内で複数の言語を使用する方法について説明する。
- [ ] あるノートブックを別のノートブック内から実行する方法を特定する。
- [ ] ノートブックを他人と共有する方法を特定する。
- [ ] Databricks Repos が Databricks 内で CI/CD ワークフローを実現する方法について説明する。
- [ ] Databricks Repos 経由で利用可能な Git の操作を特定する。
- [ ] Repos との比較で Databricks ノートブックのバージョン管理機能にどのような制限があるかを特定する。

## セクション 2: Apache Spark での ELT
- [x] 単一のファイルからのデータ抽出と、複数のファイルを含むディレクトリからのデータ抽出を行う
- [x] FROM キーワードの後ろにデータタイプとして含まれている接頭辞を特定する。
- [x] ビュー、一時ビュー、CTE をファイルの参照として作成する
- [x] 外部ソースからのテーブルが Delta Lake テーブルでないことを特定する。
- [x] JDBC 接続と外部 CSV ファイルからテーブルを作成する
- [x] count_if 関数の使用方法と、x が null のカウントの使用方法を特定する
- [x] count(row) で NULL の値をスキップする方法を特定する。
- [x] 既存の Delta Lake テーブルから行の重複を排除する。
- [x] 既存のテーブルから重複する行を削除して新しいテーブルを作成する。
- [x] 特定の列に基づいて行の重複を排除する。
- [x] すべての行に対してプライマリキーが一意であることを確認する。
- [x] フィールドが別のフィールド内の一意の値に 1 つだけ関連付けられていることを確認する。
- [x] 値が特定のフィールドにないことを確認する。
- [x] 列をタイムスタンプにキャストする。
- [x] タイムスタンプからカレンダーのデータを抽出する。
- [x] 既存の文字列列から特定のパターンを抽出する。
- [x] ドット構文を利用して、ネストされたデータフィールドを抽出する。
- [x] JSON 文字列を解析して構造体にする。
- [x] array 関数を使用するメリットを特定する。
- [x] explode 関数と flatten 関数を使用するシナリオを特定する
- [ ] 結合クエリーに基づいて返される結果を特定する。
- [ ] ワイド形式からロング形式にデータを変換する手段として PIVOT 句を特定する。
- [ ] SQL UDF を定義する。
- [ ] 関数の場所を特定する。
- [ ] SQL UDF を共有するためのセキュリティモデルについて説明する。
- [ ] SQL コードに CASE/WHEN を使用する。
- [ ] カスタム制御フローに CASE/WHEN を活用する。

## セクション 3: 増分データ処理
- [ ] Delta Lake が ACID トランザクションを提供する場所を特定する
- [ ] ACID トランザクションのメリットを特定する。
- [ ] トランザクションが ACID に準拠しているかどうかを特定する。
- [ ] データとメタデータを比較対照する。
- [ ] マネージドテーブルと外部テーブルを比較対照する。
- [ ] 外部テーブルを使用するシナリオを特定する。
- [ ] マネージドテーブルを作成する。
- [ ] テーブルの場所を特定する。
- [ ] Delta Lake ファイルのディレクトリ構造を調べる。
- [ ] 前のバージョンのテーブルを記述した人物を特定する。
- [ ] テーブルトランザクションの履歴を確認する。
- [ ] テーブルを前のバージョンにロールバックする。
- [ ] テーブルを前のバージョンにロールバックできることを特定する。
- [ ] 特定のバージョンのテーブルをクエリーする。
- [ ] Z-Ordering が Delta Lake テーブルで有益な理由を特定する。
- [ ] VACUUM でどのようにして削除がコミットされるのかを特定する。
- [ ] OPTIMIZE によって圧縮されるファイルの種類を特定する。
- [ ] CTAS をソリューションとして特定する。
- [ ] 生成された列を作成する。
- [ ] テーブルのコメントを追加する。
- [ ] CREATE OR REPLACE TABLE と INSERT OVERWRITE を使用する
- [ ] CREATE OR REPLACE TABLE と INSERT OVERWRITE を比較対照する
- [ ] MERGE を使用すべきシナリオを特定する。
- [ ] 保存時にデータの重複を排除するコマンドとして MERGE を特定する。
- [ ] MERGE コマンドのメリットを説明する。
- [ ] COPY INTO ステートメントではターゲットテーブルのデータの重複が排除されない理由を特定する。
- [ ] COPY INTO を使用すべきシナリオを特定する。
- [ ] COPY INTO を使用してデータを挿入する。
- [ ] 新しい DLT パイプラインを作成するために必要なコンポーネントを特定する。
- [ ] パイプライン作成におけるターゲットとノートブックライブラリの目的を特定する。
- [ ] コストとレイテンシーの観点から、トリガー式のパイプラインと継続的なパイプラインを比較対照する
- [ ] Auto Loader を利用しているソースの場所を特定する。
- [ ] Auto Loader が有益なシナリオを特定する。
- [ ] Auto Loader では JSON ソースから推論されたデータがすべて STRING になる理由を特定する
- [ ] 制約違反のデフォルト動作を特定する
- [ ] 制約違反に対する ON VIOLATION DROP ROW と ON VIOLATION FAIL UPDATE の影響を特定する
- [ ] チェンジデータキャプチャと、APPLY CHANGES INTO の動作について説明する
- [ ] イベントログをクエリーして、メトリクスの取得、監査ロギング、リネージの検査を行う。
- [ ] DLT 構文のトラブルシューティング: エラーを発生させた DLT パイプライン内のノートブックを特定する。CREATE ステートメントに LIVE が必要であることを特定する。FROM 句に STREAM が必要であることを特定する。

## セクション 4: 本番運用パイプライン
- [ ] ジョブで複数のタスクを使用するメリットを特定する。
- [ ] ジョブで先行タスクを設定する。
- [ ] 先行タスクを設定すべきシナリオを特定する。
- [ ] タスクの実行履歴を確認する。
- [ ] スケジューリングの機会として CRON を特定する。
- [ ] 失敗したタスクをデバッグする。
- [ ] 失敗時の再試行ポリシーを設定する。
- [ ] タスクが失敗したときのアラートを作成する。
- [ ] E メールで送信できるアラートを特定する。

## セクション 5: データガバナンス
- [ ] データガバナンスの 4 領域のいずれかを特定する。
- [ ] メタストアとカタログを比較対照する。
- [ ] Unity Catalog でセキュリティの設定が可能な内容を特定する。
- [ ] サービスプリンシパルを特定する。
- [ ] Unity Catalog と互換性がある、クラスターのセキュリティモードを特定する。
- [ ] UC が有効な All-Purpose クラスターを作成する。
- [ ] DBSQL ウェアハウスを作成する。
- [ ] 3 層の名前空間に対してクエリーを実行する方法を特定する。
- [ ] データオブジェクトのアクセスコントロールを実装する
- [ ] メタストアとワークスペースを同じ場所に配置することがベストプラクティスであると特定する。
- [ ] サービスプリンシパルを接続に使用することがベストプラクティスであると特定する。
- [ ] カタログ全体で事業部門を分けることがベストプラクティスであると特定する。


# サンプル問題

これらの問題は旧バージョンの試験から削除されたもので、試験ガイドに記載されている目的を示し、各目
的に対応するサンプル問題を提示することを意図としています。試験ガイドには、試験の出題対象になる可
能性がある目的の一覧が記載されています。認定試験の準備を行う際には、この試験ガイドの「試験の概
要」を確認することをお勧めします。
問題 1
目的: 従来のデータウェアハウスとの比較で、データレイクハウスのメリットを説明する。
従来のデータウェアハウスにはない、データレイクハウスのメリットは何ですか。
A. データレイクハウスは、データ管理のリレーショナルシステムを提供する。
B. データレイクハウスは、バージョン管理のためにスナップショットを収集する。
C. データレイクハウスは、ストレージとコンピュートを統合して完全な管理を実現する。
D. データレイクハウスは、独自のストレージフォーマットをデータに利用する。
E. データレイクハウスは、バッチ分析とストリーミング分析の両方に対応している。
問題 2
目的: クエリーの最適化手法を特定する。
データエンジニアリングチームは、Delta テーブルに対してクエリーを実行して、同じ条件を満たす行をすべ
て抽出する必要があります。しかし、チームはクエリーの実行が遅いことに気付きました。データファイルの
サイズは既に調整してあります。調査の結果、チームは、条件を満たす行が各データファイルの全体にまば
らに存在すると結論付けました。
クエリーの速度を上げられるのは、どの最適化手法ですか。
A. データスキップ
B. Z-Ordering
C. ビンパッキング
D. Parquet ファイルとして記述
E. ファイルサイズの調整
問題 3
目的: シルバーテーブルをソースとして利用するデータワークロードを特定する。
シルバーテーブルをソースとして利用するデータワークロードはどれですか。
A. タイムスタンプを解析して人間が読み取れる形式にすることで、データをエンリッチ化するジョブ
B. ダッシュボードに既にフィードされている集計済みデータに対してクエリーを実行するジョブ
C. ストリーミングソースからレイクハウスに生データを取り込むジョブ
D. クリーニングしたデータを集計して、標準的なサマリー統計を作成するジョブ
E. 異常な形式のレコードを削除してデータをクリーニングするジョブ
問題 4
目的: 更新スケジュールの構成方法を説明する
エンジニアリングマネージャーは、顧客から報告があったバグを修正するチームの進捗状況を監視するため
に、Databricks SQL クエリーを使用しています。マネージャーはクエリーの結果を毎日チェックしています
が、その日ごとにクエリーを手動で再実行して、結果が返ってくるまで待っています。
クエリーの結果が毎日更新されるようにするには、クエリーをどのようにスケジュールすべきですか。
A. Databricks SQL のクエリーのページで 12 時間ごとに更新する。
B. Databricks SQL のクエリーのページで 1 日ごとに更新する。
C. ジョブの UI で 12 時間ごとに実行する。
D. Databricks SQL の SQL ウェアハウスのページで 1 日ごとに更新する。
E. Databricks SQL の SQL ウェアハウスのページで 12 時間ごとに更新する。
問題 5
目的: 適切な権限を付与するためのコマンドを特定する
ある会社で新しいデータエンジニアが働き始めました。会社の Databricks ワークスペースに、つい先日、こ
のデータエンジニアが new.engineer@company.com として追加されました。データエンジニアは retail
データベースの sales テーブルに対してクエリーを実行できる必要があり、retail データベースに対する
USAGE 権限が既に付与されています。
新しいデータエンジニアに適切な権限を付与するには、どのコマンドを使用するべきですか。
A. GRANT USAGE ON TABLE sales TO new.engineer@company.com;
B. GRANT CREATE ON TABLE sales TO new.engineer@company.com;
C. GRANT SELECT ON TABLE sales TO new.engineer@company.com;
D. GRANT USAGE ON TABLE new.engineer@company.com TO sales;
E. GRANT SELECT ON TABLE new.engineer@company.com TO sales;
答え
問題 1: E
問題 2: B
問題 3: D
問題 4: B
問題 5: C
